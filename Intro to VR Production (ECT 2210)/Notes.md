# Intro to VR Production (ECT 2210) Notes

## Professor Info

Chip Linscott
Email: <linsoc2@ohio.edu>
Office: McClure 367

- Weds 1 PM - 3 PM
- Thurs 9 AM - 10 AM

## GTA Info

Jeffrey Agyei Agyekum
Email: <ja841221@ohio.edu>

## Books

    Stevens, Renee. Designing Immersive 3D Experiences: A Designerâ€™s Guide to Creating Realistic 3D Experiences for Extended Reality. Pearson, 2022. 
    Link: <https://alice.library.ohio.edu/search~S7/?searchtype=t&searcharg=Designing+Immersive+3D&searchscope=7&SORT=D&extended=0&SUBMIT=Search&searchlimits=&searchorigarg=tImmersive+3D+Design>

## 1-18-24

**Read Stevens 3+4 for next week**

**Type up notes from Intro to VR**

The environment doesn't need to be real, but the interactions have to be *realistic* per that world's 'rules'.

### Terms

Metaverse
: A space where users can interact with a computer generated environment and other users.

Immersion
: Objective degree to which a VR system and application projects stimuli onto the sensory receptors of users in a way that is:
    - extensive: range of sensory modalities for user
    - matching: congruence between sensory modalities
    - surrounding: extent to which cues are panoramic
    - vivid: quality of energy simulated (resolution, bit rate, frame rate, etc.)
    - interactive: user ability to change world/events, virtual entities responses to user
    - plot informing: "dealing with story, sequence of events in time, themes/messages" (Slater and Wilbur 1997, cited in Jeralds) --> events make sense within linear time

Presence
: The subjective degree to which a person feels 'in' a VR environment

Break-in-Presence
: Disruption of illusion of virtual world

## 1-23-24

Avatar Assignment due 1/30/24

Production
Making things/content -> What is content? -> Reciprocal bc content is what you make

Love to Money Continuum

Why do I want to be a Game Dev? -> Should probably come up with a concise answer

**Read Stevens 3+4 for this week**

Goals for these slides: Designing for 3D Experiences + Working in Unity

### Affordances and Multimodal Experiences in XR

XR lets you do experiences that you can't normally do.

Stevens says XR should inspire how you interact with the 'real' world. -> XR worlds should be realistic, but can be not real.

Stevens also says XR should be inspired by real world interactions.

XR experiences should engage in as many real world ways as possible.

### Primitives

3D geometric shapes that can be added, subtracted, and combined to make more complex shapes.

3D modeling is difficult at first but humans understand and perceive 3D better.

### Coordinates

Z is generally always depth, X and Y can get swapped

Things get weird in sounds design -> Z becomes height

### 3D Modeling Terms

Splines
: Called "paths" in Adobe AE
: 3D curves w/ two or more points

Extrusions
: Paths pushed into space, 2D -> 3D

Meshes
: Collections of points, edges, and faces that define an object

Polygons
: Multiple vertices and edges forming a complete geometric shape
: For modeling, polygons can be placed in 3D space

Materials
: Physical properties applied to a mesh that determine how light interacts with a surface

Textures
: Flat 2D images that form the 'skin' of a mesh

Camera
: The viewpoint of an entity in a scene

Good Design Tip -> Don't apply materials until lighting is set

Scene
: Combination of objects, environment, lighting, and camera.

Render
: Conversion of a 3D model to a 2D image that can be shown on a screen

In video, rendering is last step to make an output
In audio, rendering is the combination of the audio tracks into a single audio

## 1/30/24

Elon Musk starting up BCI, first chip implanted in a person

Gabe Newell from Valve also working or investing in BCI/similar

BCI & similar, read electrical signals from brain for input

Hawking had ALS (Lou Gehrig's Disease)

Hawking's interpreting device used eye tracking to send messages, Musk's device is supposed to operate faster than ocular input by just bypassing the medium

Feds investigated Musk's BCI after a monkey was killed playing Pong. Whistleblowers told news orgs and the company was invesigated, but FDA still cleared human trials post-investigation.

### 360 Video Issues, Possibilities, Considerations, and Gear Slides

360 Video lets a viewer control their perspective

Seems simple, but that is a significant change from normal film --> The creator fundamentally has less control over the experience the view has

Enhanced *and limited* by the fact it is capturing something in the real world or a real space

Ways to make 360 Video more interactive --> Branching choices / environment reacting to chosen perspective

### Big Q's for Course

- Am I using the technology in ways that explot its differences from other mediatic forms?
  - Common mistake with fisheye lenses / 360 camera is to put action in front of camera and not around, failing to utilize the technology
  - Past students made a funny kidnapping video that switched between static perspective (trapped in a chair) and dynamic perspective, you don't have to all-in with the new methods to fully utilize them
  - Hitchcock Mise En Scene - using perspective to isolate and emphasis events, ex: zoom in on hands when passing a pen
- Is my use of this tech engaging the potential that stems from immersion, presence, lack of fixed (or 2D), screens, etc?
  - Do we have a reason to explore or view more of the environment --> Don't make novelty where the value is ooh-ahh you can spin your head and see nothing

Real-World Content
"Content does not necessarily need to be created by artists. One way of creating VR environments is not to build content but to reuse what the real world already provides." - Jerald, p.246

### More Q's

1. What elements make up a good story?
2. How can a video or film use these elements to tell a story?
3. How can 360/VR technology enhance the capabilities of video storytelling?
   1. Idea: Horror Film using Mise En Scene, if you know where someone is looking, you know where the edge of their vision is
      1. Oh right, brain processes VR as real. Horror kind of problematic
   2. Further Idea: Diving helmet horror, 360 perspective but there is still an 'edge' to the viewer's perspective
4. What might be some technical or practical issues that arise from 360 video? Are they different from other VR/AR issues? How/why?
5. What types or genres of 360 video can you name (doc, training film, narrative, etc)? How can 360 video improve those specific genres?

### 360 Video

Standard film, television, and video limits viewers to a roughly rectangular frame.

Frames come from legacy of fine art (framed paintings + theater).

A framed image demans a rather limited spectatorial position and usually provides only a small viewing angle.

## 2/22/24

*[Sound-Image Analysis Paper](Sound-Image%20Analysis%20Paper.md) was assigned on Monday, due March 5th*

New AI - Sora, was impressive but also seemed like it was ripping Kangaroo Jack, puppy stock footage, and those old ships I had when I was kid.

Playtime - Jacques Tati
Artsy film guy with low to no dialogue movies feat bumbling old man

North by Northwest - Alfred Hitchcock
Score by Bernard Hermann, the 'godfather of music in film', he pioneered a lot of how sound is used in movies

Diagetic Sound - Sound that the characters can hear

## 2/28/24

### Q&A: Ambisonics vs Atmos, Stereo vs Binaural, Waves NX in Fairlight 

Link: <https://www.youtube.com/watch?v=R2QON1y5BCo>

### 3 Diff Perspectives for Sound

1. Sounds is a pressure distribution that is only related to your position on the 'sweet spot'.
2. Sound from an emitter (speaker)
3. Sound as it enters your ears

1st Perspective -> Ambisonic, wave function on a sphere

2nd Perspective -> Traditional speaker/stereo setup

3rd Perspective -> Audio that is rendered exactly the way that a human would hear it (Binaural)

Monitoring and understanding is important because renders of sound in Ambisonics vs Binaural are so different

Waves NX is software that is good for modeling sound to head

### Ambisonics in Reaper

Link: <https://www.youtube.com/watch?v=fc5IXiR4KiQ>

## 3/7/24

**Remember to send docs to Chip after classes**

Unity Version: 2022.3.15f1

### Head-Related Transfer Function (HRTF)

The anatomy of an individual (height, ears, skull shape, etc.) changes how audio is perceived.

Sound changes as it passes through a medium before it is transduced.

In HRTF, some frequencies are amplified, while others are attenuated.

Affected by size, position, and shape of human ears and body.

In HRTF, sounds are filtered in various ways according to the surrounding space and properties of the body and pinna (outer ear).

"If you're used to hearing the world through your own body, we can make headphones and audio that shape that."

Examples of HRTF: PS5 Spatial Audio functions, uses generalized not specific HRTF.

Two HRTFs allow for the simulation of binaural hearing in headphones.

Each person's HRTF is unique.

Endophony
: A sound you hear inside (your head) but not outside.

Intra-aural Time Difference (ITD)
: Delay between the perception of sound in oner ear versus the other.
: Perfectly centered sounds reach both ears simultaneously.
: ITD plays an important role in locating the sources of sounds in space.

## 3/19/24

### Helpful Links on Unity RPG Stuff

[Unity RPG Structure](https://forum.unity.com/threads/rpg-class-job-structure-c.396721/)

[Unity RPG Creator Kit](https://learn.unity.com/project/creator-kit-rpg)

### PORTS

Digital Twin / 3D Model of Decommissioned Nuclear Plants

### McClure School Day

**March 21 (Next Thursday), Event last all day**
**Class in Baker Center 240/242**

Michael Stevens Presentation
: Former Game Dev Teacher at OU
: Senior Gameplay Engineer
: Worked for Super7 Games
: Current Company just ran out of funding, presentation about jobs in the industry

## Unity

Marvel Snap is made with Unity

Unity 3D has more features for VR, Unreal is also good but just not oriented or expanded as much

Game Engine
: Real-time development platform used to create games, simulations, etc.

Real-time
: You can see changes as they're made, not after rendering or processing

Cross-platform
: Works for multiple OS's and devices (Windows, Mac OS, Playstation, Xbox, web, mobile, etc.)

Originally released in June 2005

2D & 3D Graphics Capabilities
VR, MR, and AR Capabilities
Massive Asset Store, many are free

Generally free to use until you start making big money

Uses C# Scripting, Unreal uses C++

Circa 2016, 90% of VR Games for Rift were Unity

As of 2021, Unity supports Visual Scripting

### Why is Unity good for XR development?

Great Cross-Platform Support
: Cross-platform support is very important because of how often new devices are released

Great Visual Workflow
: Important for rapid development, prototyping, and iteration
: Provides tools for physics simulation, SSAO (screen space ambient occlusion), dynamic shadows, visual effects and etc.
: Allows for scene layout and the integration of assets and code into interactive objects
: Everything created for Unity goes through the visual editor, but still allows for advanced custom code as well
: Intuitive Visual Interface
: Unreal probably has better graphics and lighting but is more difficult to learn

### Unity Downsides

Graphics -> Unreal wins
AAA Companies prefer Unreal
Potentially too many options in Unity
Not fully open-source
"Evolutionary messiness" (J. Hocking) -> Similar to Adobe, updates break stuff

### Using the Unity Interface

6 Parts: Project Window, Scene View, Game View, Hierarchy Window, Inspector Window, Toolbar

Scene View + Game View are within the Project Window, Scene is setup, Game is playing it

Project Window
: Access and utilize the assets for your project

Assets
: Anything you're using inside your project -> scripts, colors, images, etc.

Scene View
: Interactive window into world, position scenery, characters, cmaeras, lights, and any other types of **Game Objects**

Game View
: Rendered view from the **Cameras** in your game, represents final and playable version of the game.
: Multiple **Cameras** will be used to make different views for the player

Hierarchy Window
: Contains a list of every **Game Object** in the current **Scene**
: May include direct instances of Asset files, Prefabs

Parenting
: By default, objects are listed in the Hierarchy window in the order they are made.
: You can re-order the objects by dragging them up or down, making them child or parent objects
: Children inherit the behavior of their Parents
: Child objects inherit the movement and roation of the parent object

The Inspector
: When selecting a **GameObject**, displays all of the **Components** attached to that **GameObject**
: **GameObjects** have **Components** like scripts, sounds, meshes, and other graphical elements such as lights.

## 3-28-24

### Jorge Castillo-Castro Presentation: Digital Twins

Digital Twins
: Digital reconstruction of a thing, doesn't have to be a space.
: Digital representation of something that already exists.

Nvidia -> Working on digital twin of Earth for weather system study

How do you get the assets?
Old way was using CAD files, but it was time intensive
New way is using VR --> More Specific, using photogrammetry

*Q: Can you import CAD files into Unity / Is there a non-Blender way to make models?*

*Jorge is teaching a whole class in the Fall on Digital Twins*

*Q: What software for this ^ class?*

Photogrammetry
: Science of obtaining information about physical objects and the environment the process of recording, measuring, and interpreting photographic images.

There are different uses for photogrammetry and the workflow cna vary depending on the content.

### Workflow for Photogrammetry

Image Acquistion -> Processing -> Reconstruction -> Polishing Mesh -> Texturing

- Image Acquistion
  - This is where hardware is a big deal, having better cameras not only improves model quality but also makes process easier.
  - You take many, many, many photos simultaneously at multiple angles.
  - It is very important for the object to be evenly lit because shadows are applied in post.
  - Take images in the raw, colors are corrected in post.
- Processing
  - Adobe Lightroom
  - Color adjustments on the images so they all match
  - Masking (Silhouette) blocks all the information we don't want to use in programs further down the pipeline
- Reconstruction
  - Software
    - Agisoft Metashape -> Paid (Inventor $$$)
      - Engineering, Construction Uses
    - Meshroom -> Free
    - RealityCapture -> Pay per Model
    - PolyCamp -> Mobile
    - Luma AI -> Mobile, uses Gaussian Splats, kind of quirky
  - Mobile apps are kind of nice because they cloud process
- Polishing Mesh
  - Doing tweaks and then getting poly count down to be usable
- Texturing
  - UV Mapping: Making a map for how light is absorbed on the model
  - Textures are applied to maintain the depth/surface of object without using polygons

## 4-2-24

Blossom Hack
: 24 Hour Hackathon
: April 6-7
: Checkin @ 10 AM
: Irvine 194
: No Experience Required

### Special Classes that will only be offered once-ish!

ECT 2411 - World Creation - Alex Rossin - Fall
ECT 4900 - Photogrammetry - Jorge - Fall
ECT 4900 - Advanced CG Pipeline - Darko - Fall
: Media Design / Game Dev co-op, teaches going from art to game

### Coding in Unity

Good Structure for C#
Variables / Properties -> Funcs -> Unity Funcs

Vector3
: Set of 3 floats

Rest of presentation of Blackboard

### Half-Life: Alyx

Arguable best VR Games
Valve focus on player control -> Loss of freedom breaks presence
Freedom to Look -> Caused issues in games before, even more in VR -> Known as attention problem
Valve solves this by using audio/visual ques to direct players attention
VR exponentially compounds the attention problem
: VR lets users have full control of their perspective
: VR is also designed in a way where there has to be more to look at (good VR doesn't have blank spots behind you)

## 4-16-24

New Assign: AR Production Project
Due In-Class next Thurs

### Types of AR Interaction

- Location-based
  - AR elements are tied to geographic coordinates, like Pokemon Go
- Object-based
  - AR elements are tied to a physical object, like Museum stuff
- Proximity-based
  - AR elements perform some action based on their adjacency to another thing (including the user)

### Fungisaurs

Dinosaur + Fungus toys
Uses AR but instead of RF ID chips in the toy, the shape and color of the toy functions kind of like a QR code

### State of AR

VR it is okay to have a headset
AR to really take off requires a non-headset and non-tablet option, re: Google Glass and similar

### Human-Computer Interaction (HCI)

Three Main Types:

- Visual
  - Graphics
  - Text
  - UI
  - Screens
  - Animations
  - 2D/3D Objects
  - Eye Tracking
  - Poses
- Auditory
  - Voice
  - Sound Effects
  - Music
  - Ambience + Environmental Sounds
  - Tones
- Physical
  - Hardware
  - Game Peripherals
  - Haptics
  - External Physical Objects

HCI has existed since we've touched a computer
As tech advances, computers get smaller and closer to us
Ivan Sutherland made the GUI
